{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# training and Testing directories\n",
    "training_dir = os.path.join(\"Datasets\", \"Training\")\n",
    "testing_dir = os.path.join(\"Datasets\", \"Testing\")\n",
    "if not os.path.isdir(training_dir):\n",
    "    raise Exception(\"ERROR: training dataset not found\")\n",
    "if not os.path.isdir(testing_dir):\n",
    "    raise Exception(\"ERROR: testing dataset not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/Training/tweets_#nfl.txt\n",
      "Datasets/Training/tweets_#superbowl.txt\n",
      "Datasets/Training/tweets_#sb49.txt\n",
      "Datasets/Training/tweets_#patriots.txt\n",
      "Datasets/Training/tweets_#gohawks.txt\n",
      "Datasets/Training/tweets_#gopatriots.txt\n"
     ]
    }
   ],
   "source": [
    "# iterate over all hashtag files \n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the gopatriots dataset for testing\n",
    "# change to only_superbowl = ['superbowl'] for actual running\n",
    "\n",
    "only_superbowl = ['superbowl']\n",
    "only_gopatriots = ['gopatriots'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing superbowl...\n",
      "\t----------\n",
      "\tnumber of tweets in period: 1213813\n",
      "\t----------\n",
      "\tnumber of locations in superbowl dataset: 1213813\n",
      "\t----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing with Smaller File\n",
    "locations = []\n",
    "\n",
    "# iterate over all hashtag files \n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(file)[0].replace('tweets_#', '')\n",
    "          \n",
    "        # CHANGE TO only_superbowl for final submission\n",
    "        # Only Look at the gopatriots Data file for testing\n",
    "        if not filename in only_superbowl:\n",
    "#         if not filename in only_gopatriots:\n",
    "            continue\n",
    "        \n",
    "        print('Parsing {}...'.format(filename))\n",
    "        \n",
    "        # only extracting specific features from the tweet json objects\n",
    "        citation_dates = []\n",
    "        \n",
    "        # open the file and read all lines:\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as hashtag:\n",
    "            # read line-by-line\n",
    "            for line in hashtag:\n",
    "                json_obj = json.loads(line)\n",
    "                \n",
    "                # get citation date\n",
    "                citation_date = json_obj['citation_date']\n",
    "                citation_dates.append(citation_date)\n",
    "                \n",
    "                # get locations \n",
    "                location = json_obj['tweet']['user']['location']\n",
    "                locations.append(location)\n",
    "        \n",
    "        # processing citation feature\n",
    "        print('\\t'+'-'*10)\n",
    "        citation_dates = np.array(citation_dates)\n",
    "        print('\\tnumber of tweets in period: {}'.format(len(citation_dates)))\n",
    "        min_date = np.min(citation_dates)\n",
    "        max_date = np.max(citation_dates)\n",
    "\n",
    "        # processing all locations\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tnumber of locations in {} dataset: {}'.format(filename, len(locations)))\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique locations is: 179770\n"
     ]
    }
   ],
   "source": [
    "unique_locations = []\n",
    "\n",
    "for location in locations:\n",
    "    if location in unique_locations: # Avoid duplicates\n",
    "        continue\n",
    "\n",
    "    unique_locations.append(location)\n",
    "    \n",
    "print('number of unique locations is: {}'.format(len(unique_locations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if in MA or WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique locations in MA or WA : 5119\n",
      "----------\n",
      "number of unique locations in MA or WA after removing DC: 4650\n",
      "----------\n",
      "number of locations in MA: 2484\n",
      "----------\n",
      "number of locations in WA: 2182\n"
     ]
    }
   ],
   "source": [
    "# Define Locations\n",
    "\n",
    "MA_WA = [' MA',' WA', 'Massachusetts', 'Washington', 'Boston', 'Seattle'] # Look for all possible MA and WA matches\n",
    "# NOTE: added 'space' before MA and WA to avoid problems such as IOWA; Could do this differently\n",
    "\n",
    "all_MA_WA = [location for location in unique_locations if any(place in location for place in MA_WA)] # Create list of all places in MA and WA\n",
    "\n",
    "DC = ['DC', 'D.C.', 'D.C']\n",
    "\n",
    "all_MA_WA_no_DC = [location for location in all_MA_WA if not any(place in location for place in DC)] # remove DC and D.C.\n",
    "\n",
    "MA = [' MA', 'Massachusetts', 'Boston'] # Get just locations in Massachusetts\n",
    "WA = [' WA', 'Washington', 'Seattle'] # Get just locations in Washington\n",
    "\n",
    "only_MA = [location for location in all_MA_WA_no_DC if any(place in location for place in MA)] # Get just locations in Massachusetts\n",
    "only_WA = [location for location in all_MA_WA_no_DC if any(place in location for place in WA)] # Get just locations in Washington\n",
    "\n",
    "print('number of unique locations in MA or WA : {}'.format(len(all_MA_WA)))\n",
    "print('-'*10)\n",
    "print('number of unique locations in MA or WA after removing DC: {}'.format(len(all_MA_WA_no_DC)))\n",
    "print('-'*10)\n",
    "print('number of locations in MA: {}'.format(len(only_MA)))\n",
    "print('-'*10)\n",
    "print('number of locations in WA: {}'.format(len(only_WA)))\n",
    "\n",
    "# print('-'*10)\n",
    "# print('Locations in MA and WA: ','\\n', *all_MA_WA_no_DC, sep = \"\\n\")\n",
    "# print('-'*10)\n",
    "# print('Locations in MA: ','\\n', *only_MA, sep = \"\\n\")\n",
    "# print('-'*10)\n",
    "# print('Locations in WA: ','\\n', *only_WA, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all tweets from WA or MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing superbowl...\n",
      "\t----------\n",
      "\tNumber of texts in superbowl dataset: 37058\n",
      "\t----------\n",
      "\tNumber of tweets from MA and WA is: 37058\n",
      "\t----------\n",
      "\tNumber of tweets from MA is:  19815\n",
      "\t----------\n",
      "\tNumber of tweets from WA is:  17243\n"
     ]
    }
   ],
   "source": [
    "# Extract all tweets from WA or MA\n",
    "\n",
    "# Testing with Smaller File\n",
    "\n",
    "# Store textual data and location labels 0 if MA 1 if WA \n",
    "tweet_textual_data = [] \n",
    "tweet_location_labels = []\n",
    "\n",
    "# Initialize counting variables to keep track of number of tweets from MA and WA\n",
    "num_tweets_MA = 0\n",
    "num_tweets_WA = 0\n",
    "\n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(file)[0].replace('tweets_#', '')\n",
    "          \n",
    "        # CHANGE TO only_superbowl for final submission\n",
    "        # Only Look at the gopatriots Data file for testing\n",
    "        if not filename in only_superbowl:\n",
    "#         if not filename in only_gopatriots:\n",
    "            continue\n",
    "        \n",
    "        print('Parsing {}...'.format(filename))\n",
    "        \n",
    "        # only extracting specific features from the tweet json objects\n",
    "        \n",
    "        # open the file and read all lines:\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as hashtag:\n",
    "            # read line-by-line\n",
    "            for line in hashtag:\n",
    "                json_obj = json.loads(line)\n",
    "                \n",
    "                # get tweets that are only in MA and WA (not DC)\n",
    "                location = json_obj['tweet']['user']['location']\n",
    "                \n",
    "                if not any(MAWA in location for MAWA in all_MA_WA_no_DC):\n",
    "                    continue\n",
    "                \n",
    "                if any (loc in location for loc in only_MA):\n",
    "                    # get textual data\n",
    "                    text = json_obj['tweet']['text'] \n",
    "                    tweet_textual_data.append(text)\n",
    "                    \n",
    "                    # add location is in MA (0)\n",
    "                    tweet_location_labels.append(0)\n",
    "                    \n",
    "                    num_tweets_MA += 1\n",
    "                    \n",
    "                if any (loc in location for loc in only_WA):\n",
    "                    if any (loc in location for loc in DC): # Check if contains DC\n",
    "                        continue\n",
    "                        \n",
    "                    # get textual data\n",
    "                    text = json_obj['tweet']['text'] \n",
    "                    tweet_textual_data.append(text)\n",
    "                \n",
    "                    # add location is in WA (1)\n",
    "                    tweet_location_labels.append(1)\n",
    "                                         \n",
    "                    num_tweets_WA += 1    \n",
    "                    \n",
    "        # process textual data\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of texts in {} dataset: {}'.format(filename, len(tweet_textual_data)))\n",
    "        \n",
    "        # Process MA and WA locations\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from MA and WA is: {}'.format(len(tweet_location_labels)))\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from MA is: ', num_tweets_MA)\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from WA is: ', num_tweets_WA)\n",
    "        \n",
    "#         print('\\t'+'-'*10)\n",
    "#         print('\\tTextual data looks like: ', *tweet_textual_data, sep = \"\\n\")\n",
    "        \n",
    "#         print('\\t'+'-'*10)\n",
    "#         print('\\tLabels look like: ', tweet_location_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_location_labels = np.asarray(tweet_location_labels)\n",
    "\n",
    "class_names = ['Massachusetts', \"Washington\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of tweets per locations\n",
    "\n",
    "plt.bar([0,1],[num_tweets_MA, num_tweets_WA])\n",
    "plt.xticks([0,1], class_names)\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.title(\"Tweets Per Location\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing datasets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.asarray(tweet_textual_data)\n",
    "y = tweet_location_labels\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "for trainset, testset in kf.split(X):\n",
    "    X_train, X_test = X[trainset], X[testset]\n",
    "    y_train, y_test = y[trainset], y[testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization & Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization functions used by CountVectorizer\n",
    "\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                  'VB': 'v', 'RB': 'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "def isfloat(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if not isfloat(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push lemmatized documents through CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33353, 6680)\n",
      "(3705, 6680)\n"
     ]
    }
   ],
   "source": [
    "# Report shapes of TF-IDF matrices\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_tfidf = tfidf_transformer.fit_transform(X_lemmatized_train_counts)\n",
    "print(X_lemmatized_train_tfidf.shape)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_tfidf = tfidf_transformer.transform(X_lemmatized_test_counts)\n",
    "print(X_lemmatized_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33353, 50)\n",
      "(50, 6680)\n"
     ]
    }
   ],
   "source": [
    "# Perform NMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=42)\n",
    "W_nmf_train_reduced = model.fit_transform(X_lemmatized_train_tfidf)\n",
    "H_nmf_train_reduced = model.components_\n",
    "\n",
    "print(W_nmf_train_reduced.shape)\n",
    "print(H_nmf_train_reduced.shape)\n",
    "\n",
    "W_nmf_test_reduced = model.transform(X_lemmatized_test_tfidf)\n",
    "H_nmf_test_reduced = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33353, 50)\n",
      "(50, 6680)\n",
      "(33353, 50)\n",
      "(50, 6680)\n"
     ]
    }
   ],
   "source": [
    "# Perform LSI using the truncated SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_lsi_train_reduced = svd.fit_transform(X_lemmatized_train_tfidf)\n",
    "Y_lsi_train_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)\n",
    "\n",
    "X_lsi_test_reduced = svd.transform(X_lemmatized_test_tfidf)\n",
    "Y_lsi_test_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e77ccd8b03c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare LSI and NMF (Training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnmf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lemmatized_train_tfidf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_nmf_train_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_nmf_train_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlsi_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lemmatized_train_tfidf\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lsi_train_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_lsi_train_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_sub_dense\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sub_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rsub_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtodense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \"\"\"\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compare LSI and NMF (Training)\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(W_nmf_train_reduced, H_nmf_train_reduced), 'fro')**2\n",
    "lsi_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(X_lsi_train_reduced, Y_lsi_train_reduced), 'fro')**2\n",
    "\n",
    "print('NMF: ', nmf_val)\n",
    "print('LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LSI and NMF (Testing)\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_test_tfidf - np.matmul(W_nmf_test_reduced, H_nmf_test_reduced), 'fro')**2\n",
    "lsi_val = np.linalg.norm(X_lemmatized_test_tfidf - np.matmul(X_lsi_test_reduced, Y_lsi_test_reduced), 'fro')**2\n",
    "\n",
    "print('NMF: ', nmf_val)\n",
    "print('LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from scikit-learn website: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SVM with Hard and Soft Margin, (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 2 linear SVMs using LSI\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# hard margin\n",
    "gamma_1 = 1000\n",
    "clf_svc_1 = LinearSVC(C=gamma_1,max_iter=100000).fit(X_lsi_train_reduced, y_train)\n",
    "predicted_svc_1 = clf_svc_1.predict(X_lsi_test_reduced)\n",
    "\n",
    "# using max_iter=100000 because otherwise the hard margin classifier does not converge\n",
    "\n",
    "#soft margin\n",
    "gamma_2 = 0.0001\n",
    "clf_svc_2 = LinearSVC(C=gamma_2,max_iter=100000).fit(X_lsi_train_reduced, y_train)\n",
    "predicted_svc_2 = clf_svc_2.predict(X_lsi_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 SVM Hard Margin Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores for the hard margin\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix for linear SVM hard margin: \\n', confusion_matrix(twenty_test_binary_labels, predicted_svc_1))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_1), classes=class_names)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_1), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy for linear SVM hard margin: ', accuracy_score(y_test, predicted_svc_1))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score for linear SVM hard margin: ', precision_score(y_test, predicted_svc_1))\n",
    "print('Recall score for linear SVM hard margin: ', recall_score(y_test, predicted_svc_1))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score for linear SVM hard margin:', f1_score(y_test, predicted_svc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for hard margin SVM\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_svc_1 = clf_svc_1.decision_function(X_lsi_test_reduced)\n",
    "fpr_svc_1, tpr_svc_1, thresholds_svc_1 = roc_curve(y_test, score_svc_1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_svc_1, tpr_svc_1)\n",
    "plt.title('ROC curve for hard margin linear SVM')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_svc_1))\n",
    "plt.xlabel('false positive rate for hard margin linear SVM')\n",
    "plt.ylabel('true positive rate for hard margin linear SVM')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 SVM Soft Margin Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores for the soft margin\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix for linear SVM soft margin: \\n', confusion_matrix(twenty_test_binary_labels, predicted_svc_2))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_2), classes=class_names)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_2), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy for linear SVM soft margin: ', accuracy_score(y_test, predicted_svc_2))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score for linear SVM soft margin: ', precision_score(y_test, predicted_svc_2))\n",
    "print('Recall score for linear SVM soft margin: ', recall_score(y_test, predicted_svc_2))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score for linear SVM soft margin:', f1_score(y_test, predicted_svc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for soft margin SVM\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_svc_2 = clf_svc_2.decision_function(X_lsi_test_reduced)\n",
    "fpr_svc_2, tpr_svc_2, thresholds_svc_2 = roc_curve(y_test, score_svc_2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_svc_2, tpr_svc_2)\n",
    "plt.title('ROC curve for soft margin linear SVM')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_svc_2))\n",
    "plt.xlabel('false positive rate for soft margin linear SVM')\n",
    "plt.ylabel('true positive rate for soft margin linear SVM')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Logistic Regression without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an unregularized logistic regression classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To be unregularized, we make the inverse of the regularization strength C \n",
    "# to be large to approximate an unregularized classifier.\n",
    "clf = LogisticRegression(random_state=42, C=500, max_iter=100, solver='lbfgs').fit(X_lsi_train_reduced, y_train)\n",
    "\n",
    "# score = clf.decision_function(X_lsi_test_reduced)\n",
    "predicted = clf.predict(X_lsi_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Logistic Regression without Regularization Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix: \\n', confusion_matrix(twenty_test_binary_labels, predicted))\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predicted))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score: ', precision_score(y_test, predicted))\n",
    "print('Recall score: ', recall_score(y_test, predicted))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score:', f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = clf.decision_function(X_lsi_test_reduced)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score))\n",
    "plt.title('ROC curve for unregularized logistic regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression With L1 & L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Define training and testing data sets\n",
    "X_train = X_lsi_train_reduced\n",
    "X_test = X_lsi_test_reduced\n",
    "\n",
    "# Define regularization strength values here\n",
    "REG_STRENGTH_OPTIONS = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Determine regulation strength for L1 regulation\n",
    "clf_L1 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l1', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "l1_reg_strength = 1/clf_L1.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L1 = clf_L1.predict(X_test)\n",
    "\n",
    "# Display L1 Stats\n",
    "print('Optimal regularization strength for L1 Regulation: ', l1_reg_strength)\n",
    "print('Accuracy with L1 Regulation for L1 Regulation: ', clf_L1.score(X_test, y_test))\n",
    "print('Average precision-recall score for L1 Regulation:', average_precision_score(y_test, predicted_L1))\n",
    "print('Precision score for L1 Regulation: ', precision_score(y_test, predicted_L1))\n",
    "print('Recall score for L1 Regulation: ', recall_score(y_test, predicted_L1))\n",
    "print('F-1 score for L1 Regulation:', f1_score(y_test, predicted_L1))\n",
    "\n",
    "# L1 ROC Curve\n",
    "score_L1 = clf_L1.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L1 Regularized Logistic Regression')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_L1))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()\n",
    "\n",
    "# Determine regulation strength for L2 regulation\n",
    "clf_L2 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l2', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "L2_reg_strength = 1/clf_L2.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L2 = clf_L2.predict(X_test)\n",
    "\n",
    "# Display L2 Stats\n",
    "print('\\nOptimal regularization strength for L2 regulation: ', L2_reg_strength)\n",
    "print('Accuracy with L2 Regulation: ', clf_L2.score(X_test, y_test))\n",
    "print('Average precision-recall score for L2 Regulation:', average_precision_score(y_test, predicted_L2))\n",
    "print('Precision score for L2 Regulation: ', precision_score(y_test, predicted_L2))\n",
    "print('Recall score for L2 Regulation: ', recall_score(y_test, predicted_L2))\n",
    "print('F-1 score for L2 Regulation:', f1_score(y_test, predicted_L2))\n",
    "\n",
    "# L2 ROC Curve\n",
    "score_L2 = clf_L2.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L2 Regularized Logistic Regression')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_L2))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes Gaussian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stats for GaussianNB using LSI for reduction\n",
    "\n",
    "# Define training and testing data sets\n",
    "X_train = X_lsi_train_reduced\n",
    "X_test = X_lsi_test_reduced\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Display GNB Stats\n",
    "print('Accuracy for Gaussian NB from LSI: ', clf.score(X_test, y_test))\n",
    "print('Average precision-recall score for Gaussian NB from LSI:', average_precision_score(y_test, predicted))\n",
    "print('Precision score for Gaussian NB from LSI: ', precision_score(y_test, predicted))\n",
    "print('Recall score for Gaussian NB from LSI: ', recall_score(y_test, predicted))\n",
    "print('F-1 score for Gaussian NB from LSI:', f1_score(y_test, predicted))\n",
    "\n",
    "# GNB ROC Curve\n",
    "prob_score = clf.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_score[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for Gaussian NB from LSI')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, prob_score[:, 1]))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
