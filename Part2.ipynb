{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pytz\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing directories\n",
    "training_dir = os.path.join(\"Datasets\", \"Training\")\n",
    "testing_dir = os.path.join(\"Datasets\", \"Testing\")\n",
    "if not os.path.isdir(training_dir):\n",
    "    raise Exception(\"ERROR: training dataset not found\")\n",
    "if not os.path.isdir(testing_dir):\n",
    "    raise Exception(\"ERROR: testing dataset not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/Training/tweets_#nfl.txt\n",
      "Datasets/Training/tweets_#superbowl.txt\n",
      "Datasets/Training/tweets_#sb49.txt\n",
      "Datasets/Training/tweets_#patriots.txt\n",
      "Datasets/Training/tweets_#gohawks.txt\n",
      "Datasets/Training/tweets_#gopatriots.txt\n"
     ]
    }
   ],
   "source": [
    "# iterate over all hashtag files \n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries and Unix times for Feb 1, 8 am and Feb 1, 8 pm. \n",
    "# Dictionary keys: hashtag.\n",
    "# Dictionary values: [time of tweet (Unix), number of retweets for tweet, number of followers for tweeter]\n",
    "# Each row in dictionary value is an individual tweet.\n",
    "\n",
    "hashtag_dict_before = {}\n",
    "hashtag_dict_during = {}\n",
    "hashtag_dict_after = {}\n",
    "start_unix_time = 1422806400 # 8 am, Feb 1, PST\n",
    "end_unix_time = 1422849600 # 8 pm, Feb 1, PST\n",
    "pst_tz = pytz.timezone('America/Los_Angeles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing nfl...\n",
      "Parsing superbowl...\n",
      "Parsing sb49...\n",
      "Parsing patriots...\n",
      "Parsing gohawks...\n",
      "Parsing gopatriots...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Parse files to get necessary data \"\"\"\n",
    "\n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(file)[0].replace('tweets_#', '')\n",
    "        print('Parsing {}...'.format(filename))\n",
    "        \n",
    "        hashtag_dict_before[filename] = []\n",
    "        hashtag_dict_during[filename] = []\n",
    "        hashtag_dict_after[filename] = []\n",
    "        \n",
    "        # open the file and read all lines:\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as hashtag:\n",
    "            # read line-by-line\n",
    "            for line in hashtag:\n",
    "                json_obj = json.loads(line)\n",
    "                \n",
    "                # get desired statistics\n",
    "                citation_date = json_obj['citation_date'] # Unix time\n",
    "                num_retweets = json_obj['metrics']['citations']['total'] # Number of retweets for this tweet\n",
    "                num_followers = json_obj['author']['followers'] # Number of followers for tweeter\n",
    "                \n",
    "                # Check when tweet was made and add it to corresponding dictionary\n",
    "                if citation_date < start_unix_time:\n",
    "                    hashtag_dict_before[filename].append([citation_date, num_retweets, num_followers])\n",
    "                elif citation_date > end_unix_time:\n",
    "                    hashtag_dict_after[filename].append([citation_date, num_retweets, num_followers])\n",
    "                else:\n",
    "                    hashtag_dict_during[filename].append([citation_date, num_retweets, num_followers])\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Data\n",
    "\n",
    "##### Variables:\n",
    "<span>\n",
    "key = one of the hashtags <br \\> <br \\>\n",
    "</span>\n",
    "\n",
    "<span>\n",
    "data_hashtag_before[key] = data before 2/1 8am, split into 1-hour windows (separated by hashtag) <br \\>\n",
    "data_hashtag_during[key] = data between 2/1 8am and 8pm, split into 5-min windows (separated by hashtag) <br \\>\n",
    "data_hashtag_after[key] = data after 2/1 8pm, split into 1-hour windows (separated by hashtag) <br \\> <br \\>\n",
    "</span>\n",
    "\n",
    "<span>\n",
    "data_aggregate_before = data before 2/1 8am, split into 1-hour windows (all hashtags combined) <br \\>\n",
    "data_aggregate_during = data between 2/1 8am and 8pm, split into 5-min windows (all hashtags combined) <br \\>\n",
    "data_aggregate_after = data after 2/1 8pm, split into 1-hour windows (all hashtags combined) <br \\> <br \\>\n",
    "</span>\n",
    "\n",
    "<span>\n",
    "data_hashtag_all[key] = all data, split into 1-hour windows (separated by hashtag) <br \\> <br \\>\n",
    "</span>\n",
    "\n",
    "<span>\n",
    "data_all = all data, split into 1-hour windows (all hashtags combined) <br \\>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly list hashtags. \n",
    "# Convert each value in dictionary to numpy arrays.\n",
    "\n",
    "hashtags = ['gohawks', 'gopatriots', 'nfl', 'patriots', 'sb49', 'superbowl']\n",
    "\n",
    "for key in hashtags:\n",
    "    hashtag_dict_before[key] = np.array(hashtag_dict_before[key])\n",
    "    hashtag_dict_during[key] = np.array(hashtag_dict_during[key])\n",
    "    hashtag_dict_after[key] = np.array(hashtag_dict_after[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many time windows there are\n",
    "\n",
    "ftt = int(np.min([np.min(hashtag_dict_before[key][:,0]) for key in hashtags])) # first tweet time\n",
    "ltt = int(np.max([np.max(hashtag_dict_after[key][:,0]) for key in hashtags])) # last tweet time\n",
    "\n",
    "num_windows_before = int(np.max([((start_unix_time - ftt) // 3600) + 1 for key in hashtags]))\n",
    "num_windows_during = int(np.max([((end_unix_time - start_unix_time) // 3600 * 12) for key in hashtags]))\n",
    "num_windows_after = int(np.max([((ltt - end_unix_time) // 3600) + 1 for key in hashtags]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gohawks\n",
      "gopatriots\n",
      "nfl\n",
      "patriots\n",
      "sb49\n",
      "superbowl\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Organize data into specific time periods:\n",
    "     before 2/1 8am with 1-hour windows, \n",
    "     between 2/1 8am and 2/1 8pm with 5-min windows,\n",
    "     and after 2/1 8pm with 1-hour windows \"\"\"\n",
    "\n",
    "# Initialize dictionary for each time frame.\n",
    "data_hashtag_before = {}\n",
    "data_hashtag_during = {}\n",
    "data_hashtag_after = {}\n",
    "\n",
    "# Iterate through each hashtag.\n",
    "for key in hashtags:\n",
    "    print(key)\n",
    "    \n",
    "    # Rename the dictionary value for readability\n",
    "    temp_before = hashtag_dict_before[key]\n",
    "    temp_during = hashtag_dict_during[key]\n",
    "    temp_after = hashtag_dict_after[key]\n",
    "    \n",
    "    data_hashtag_before[key] = np.zeros((num_windows_before, 5)) # Initialize array: rows = time window, columns = feature\n",
    "    num_followers_before = {} # Initialize dictionary to count # of followers for each tweet\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Iterate through all elements before start time\n",
    "    for i in range(np.shape(temp_before)[0]):\n",
    "        # Get row number\n",
    "        item_before = int(num_windows_before - 1 - ((start_unix_time - temp_before[i,0] - 1) // 3600))\n",
    "        # Update first 3 elements (# of tweets, total # retweets, total # followers)\n",
    "        data_hashtag_before[key][item_before] += np.array([1, int(temp_before[i, 1]), int(temp_before[i, 2]), 0, 0])\n",
    "        # Get time of day (hour)\n",
    "        dt_obj_pst = datetime.fromtimestamp(temp_before[i,0], pst_tz)\n",
    "        data_hashtag_before[key][item_before][4] = int(datetime.strftime(dt_obj_pst, '%H'))\n",
    "        # Get number of followers\n",
    "        if item_before not in num_followers_before.keys():\n",
    "            num_followers_before[item_before] = []\n",
    "        num_followers_before[item_before].append(temp_before[i,2])\n",
    "    for i in num_followers_before.keys():\n",
    "        data_hashtag_before[key][i][3] = np.max(num_followers_before[i])\n",
    "        \n",
    "        \n",
    "    # Iterate through all elements during time\n",
    "    data_hashtag_during[key] = np.zeros((num_windows_during, 5))\n",
    "    num_followers_during = {}\n",
    "    for i in range(np.shape(temp_during)[0]):\n",
    "        item_during = int(((temp_during[i,0] - start_unix_time) * 12) // 3600)\n",
    "        data_hashtag_during[key][item_during] += np.array([1, int(temp_during[i, 1]), int(temp_during[i, 2]), 0, 0])\n",
    "        dt_obj_pst = datetime.fromtimestamp(temp_during[i,0], pst_tz)\n",
    "        data_hashtag_during[key][item_during][4] = int(datetime.strftime(dt_obj_pst, '%H'))\n",
    "        \n",
    "        if item_during not in num_followers_during.keys():\n",
    "            num_followers_during[item_during] = []\n",
    "        num_followers_during[item_during].append(temp_during[i,2])\n",
    "    for i in num_followers_during.keys():\n",
    "        data_hashtag_during[key][i][3] = np.max(num_followers_during[i])\n",
    "        \n",
    "    # Iterate through all elements after end time\n",
    "    data_hashtag_after[key] = np.zeros((num_windows_after, 5))\n",
    "    num_followers_after = {}\n",
    "    for i in range(np.shape(temp_after)[0]):\n",
    "        item_after = int((temp_after[i,0] - end_unix_time) // 3600)\n",
    "        data_hashtag_after[key][item_after] += np.array([1, int(temp_after[i, 1]), int(temp_after[i, 2]), 0, 0])\n",
    "        dt_obj_pst = datetime.fromtimestamp(temp_after[i,0], pst_tz)\n",
    "        data_hashtag_after[key][item_after][4] = int(datetime.strftime(dt_obj_pst, '%H'))\n",
    "        \n",
    "        if item_after not in num_followers_after.keys():\n",
    "            num_followers_after[item_after] = []\n",
    "        num_followers_after[item_after].append(temp_after[i,2])\n",
    "    for i in num_followers_after.keys():\n",
    "        data_hashtag_after[key][i][3] = np.max(num_followers_after[i])\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aggregate data within each time period by combining all hashtags. \"\"\"\n",
    "\n",
    "# Initialize aggregated data variables\n",
    "data_aggregate_before = np.zeros([num_windows_before, 5])\n",
    "data_aggregate_during = np.zeros([num_windows_during, 5])\n",
    "data_aggregate_after = np.zeros([num_windows_after, 5])\n",
    "\n",
    "# Sum the # of tweets, total # of retweets, and # of followers\n",
    "for key in hashtags:\n",
    "    data_aggregate_before[:,0:3] += data_hashtag_before[key][:,0:3]\n",
    "    data_aggregate_during[:,0:3] += data_hashtag_during[key][:,0:3]\n",
    "    data_aggregate_after[:,0:3] += data_hashtag_after[key][:,0:3]\n",
    "# Find the max # of followers for each\n",
    "data_aggregate_before[:,3] = np.amax([data_hashtag_before[key][:,3] for key in hashtags], axis=0)\n",
    "data_aggregate_during[:,3] = np.amax([data_hashtag_during[key][:,3] for key in hashtags], axis=0)\n",
    "data_aggregate_after[:,3] = np.amax([data_hashtag_after[key][:,3] for key in hashtags], axis=0)\n",
    "\n",
    "# Copy over the same time frames\n",
    "data_aggregate_before[:,4] = data_hashtag_before['superbowl'][:,4]\n",
    "data_aggregate_during[:,4] = data_hashtag_during['superbowl'][:,4]\n",
    "data_aggregate_after[:,4] = data_hashtag_after['superbowl'][:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get data for the whole time frame with 1-hour windows, separated by hashtag \"\"\"\n",
    "\n",
    "# Initialize dictionary to store data.\n",
    "# Key: hashtag\n",
    "# Value: data separated by 1-hour time windows\n",
    "data_hashtag_all = {}\n",
    "\n",
    "for key in hashtags: # Iterate through all hashtags\n",
    "    temp_during = np.zeros([12, 5]) # Initialize array to store data in the middle time period\n",
    "    # Combine data in the middle time period\n",
    "    for i in range(np.shape(data_hashtag_during[key])[0]):\n",
    "        hour = int(data_hashtag_during[key][i,4] - 8)\n",
    "        temp_during[hour, :3] += data_hashtag_during[key][i, :3]\n",
    "        if not i % 12:\n",
    "            temp_during[hour, 3] = np.max(data_hashtag_during[key][i:(i+12), 3])\n",
    "            temp_during[hour, 4] = data_hashtag_during[key][i,4]\n",
    "    data_hashtag_all[key] = np.vstack((data_hashtag_before[key], temp_during, data_hashtag_after[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Combine data for the whole time frame from all hashtags \"\"\"\n",
    "\n",
    "data_all = np.zeros([587, 5])\n",
    "for key in hashtags:\n",
    "    data_all += data_hashtag_all[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hashtag_all['gohawks'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get MSE for a given linear regression model.\n",
    "\n",
    "def analyze_lr(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, predicted)\n",
    "    mse_train = mean_squared_error(y_train, model.predict(X_train))\n",
    "    r2_test = r2_score(y_test, predicted) \n",
    "    r2_train = r2_score(y_train, model.predict(X_train))\n",
    "    print('MSE:\\n   train = {} \\n test = {}'.format(mse_train, mse_test))\n",
    "    print('R2 measure:\\n   train = {} \\n test = {}'.format(r2_train, r2_test))\n",
    "    print('-------------')\n",
    "    \n",
    "    return mse_train, mse_test, r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: gohawks\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 512854.09161298693 \n",
      " test = 1643083.6454898382\n",
      "R2 measure:\n",
      "   train = 0.5894615560402771 \n",
      " test = -0.01977055384621429\n",
      "-------------\n",
      "Hashtag: gopatriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 29130.353089517917 \n",
      " test = 38710.86492773072\n",
      "R2 measure:\n",
      "   train = 0.5908426847942497 \n",
      " test = 0.48165839101775254\n",
      "-------------\n",
      "Hashtag: nfl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 216423.0911017843 \n",
      " test = 369706.1940656257\n",
      "R2 measure:\n",
      "   train = 0.6521821001784506 \n",
      " test = 0.4186028525845885\n",
      "-------------\n",
      "Hashtag: patriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 5960160.941102434 \n",
      " test = 6940065.266194089\n",
      "R2 measure:\n",
      "   train = 0.6150192147389092 \n",
      " test = 0.5598738869099552\n",
      "-------------\n",
      "Hashtag: sb49\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 24629712.20773327 \n",
      " test = 30924517.778785758\n",
      "R2 measure:\n",
      "   train = 0.7529686008713817 \n",
      " test = 0.5224832456591395\n",
      "-------------\n",
      "Hashtag: superbowl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "MSE:\n",
      "   train = 65690240.83719405 \n",
      " test = 64436708.78616054\n",
      "R2 measure:\n",
      "   train = 0.8159276434208532 \n",
      " test = 0.6147176519041198\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Analyze tweets before start time.\n",
    "\n",
    "mses = []\n",
    "mses_train = []\n",
    "r2_test = []\n",
    "r2_train = []\n",
    "\n",
    "# Define train data and targets\n",
    "for tagg in hashtags:\n",
    "    y = data_hashtag_all[tagg][1:,0] # Number of tweets (except first)\n",
    "    X = np.delete(data_hashtag_all[tagg], -1, 0) # Delete last row\n",
    "    print('Hashtag: '+ tagg)\n",
    "    print('X shape:', X.shape)\n",
    "    print('y shape:', y.shape)\n",
    "    model = LinearRegression()\n",
    "    mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: gohawks\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     118.1\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):           4.31e-86\n",
      "Time:                        03:56:22   Log-Likelihood:                -4795.4\n",
      "No. Observations:                 586   AIC:                             9601.\n",
      "Df Residuals:                     581   BIC:                             9623.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.2853      0.163      7.896      0.000       0.966       1.605\n",
      "x2            -0.1379      0.043     -3.193      0.001      -0.223      -0.053\n",
      "x3            -0.0002   7.95e-05     -2.449      0.015      -0.000   -3.85e-05\n",
      "x4           7.09e-05      0.000      0.479      0.632      -0.000       0.000\n",
      "x5             7.6320      2.943      2.593      0.010       1.852      13.412\n",
      "==============================================================================\n",
      "Omnibus:                      926.105   Durbin-Watson:                   2.214\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           804335.377\n",
      "Skew:                           8.637   Prob(JB):                         0.00\n",
      "Kurtosis:                     183.676   Cond. No.                     2.15e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.15e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "Hashtag: gopatriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.637\n",
      "Model:                            OLS   Adj. R-squared:                  0.634\n",
      "Method:                 Least Squares   F-statistic:                     204.2\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):          2.12e-125\n",
      "Time:                        03:56:22   Log-Likelihood:                -3821.6\n",
      "No. Observations:                 586   AIC:                             7653.\n",
      "Df Residuals:                     581   BIC:                             7675.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3090      0.282      1.098      0.273      -0.244       0.862\n",
      "x2             0.4908      0.190      2.587      0.010       0.118       0.863\n",
      "x3            -0.0001      0.000     -0.528      0.598      -0.001       0.000\n",
      "x4         -1.935e-05      0.000     -0.089      0.929      -0.000       0.000\n",
      "x5             0.4994      0.613      0.815      0.416      -0.704       1.703\n",
      "==============================================================================\n",
      "Omnibus:                      493.348   Durbin-Watson:                   1.907\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           309340.772\n",
      "Skew:                           2.494   Prob(JB):                         0.00\n",
      "Kurtosis:                     115.447   Cond. No.                     3.42e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.42e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "Hashtag: nfl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.652\n",
      "Model:                            OLS   Adj. R-squared:                  0.649\n",
      "Method:                 Least Squares   F-statistic:                     217.8\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):          1.21e-130\n",
      "Time:                        03:56:22   Log-Likelihood:                -4499.9\n",
      "No. Observations:                 586   AIC:                             9010.\n",
      "Df Residuals:                     581   BIC:                             9032.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.6315      0.134      4.716      0.000       0.368       0.895\n",
      "x2            -0.1811      0.064     -2.831      0.005      -0.307      -0.055\n",
      "x3             0.0001    2.5e-05      4.257      0.000    5.73e-05       0.000\n",
      "x4         -9.968e-05   3.28e-05     -3.040      0.002      -0.000   -3.53e-05\n",
      "x5             7.5806      1.966      3.855      0.000       3.719      11.442\n",
      "==============================================================================\n",
      "Omnibus:                      619.693   Durbin-Watson:                   2.363\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           342014.314\n",
      "Skew:                           3.928   Prob(JB):                         0.00\n",
      "Kurtosis:                     121.092   Cond. No.                     3.91e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.91e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "Hashtag: patriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.679\n",
      "Model:                            OLS   Adj. R-squared:                  0.677\n",
      "Method:                 Least Squares   F-statistic:                     246.3\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):          5.98e-141\n",
      "Time:                        03:56:22   Log-Likelihood:                -5361.9\n",
      "No. Observations:                 586   AIC:                         1.073e+04\n",
      "Df Residuals:                     581   BIC:                         1.076e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.9148      0.071     12.943      0.000       0.776       1.054\n",
      "x2            -0.0675      0.058     -1.170      0.243      -0.181       0.046\n",
      "x3         -1.156e-05   2.63e-05     -0.439      0.661   -6.32e-05    4.01e-05\n",
      "x4             0.0001   9.08e-05      1.489      0.137   -4.31e-05       0.000\n",
      "x5             5.2220      7.843      0.666      0.506     -10.182      20.626\n",
      "==============================================================================\n",
      "Omnibus:                      884.481   Durbin-Watson:                   1.996\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           688343.951\n",
      "Skew:                           7.876   Prob(JB):                         0.00\n",
      "Kurtosis:                     170.163   Cond. No.                     6.81e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.81e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "Hashtag: sb49\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.808\n",
      "Model:                            OLS   Adj. R-squared:                  0.807\n",
      "Method:                 Least Squares   F-statistic:                     489.8\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):          1.20e-205\n",
      "Time:                        03:56:22   Log-Likelihood:                -5693.4\n",
      "No. Observations:                 586   AIC:                         1.140e+04\n",
      "Df Residuals:                     581   BIC:                         1.142e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.1373      0.087     13.085      0.000       0.967       1.308\n",
      "x2            -0.1618      0.078     -2.065      0.039      -0.316      -0.008\n",
      "x3          9.878e-06   1.25e-05      0.793      0.428   -1.46e-05    3.43e-05\n",
      "x4          9.885e-05   4.32e-05      2.287      0.023     1.4e-05       0.000\n",
      "x5            -3.5201     14.211     -0.248      0.804     -31.432      24.391\n",
      "==============================================================================\n",
      "Omnibus:                     1187.546   Durbin-Watson:                   1.673\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2242985.837\n",
      "Skew:                          14.598   Prob(JB):                         0.00\n",
      "Kurtosis:                     304.680   Cond. No.                     6.78e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.78e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "Hashtag: superbowl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.803\n",
      "Model:                            OLS   Adj. R-squared:                  0.801\n",
      "Method:                 Least Squares   F-statistic:                     473.8\n",
      "Date:                Tue, 19 Mar 2019   Prob (F-statistic):          2.80e-202\n",
      "Time:                        03:56:22   Log-Likelihood:                -6039.9\n",
      "No. Observations:                 586   AIC:                         1.209e+04\n",
      "Df Residuals:                     581   BIC:                         1.211e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             2.2765      0.080     28.559      0.000       2.120       2.433\n",
      "x2            -0.2553      0.046     -5.595      0.000      -0.345      -0.166\n",
      "x3            -0.0001   2.19e-05     -6.278      0.000      -0.000   -9.44e-05\n",
      "x4             0.0007      0.000      5.013      0.000       0.000       0.001\n",
      "x5           -29.0126     26.714     -1.086      0.278     -81.480      23.455\n",
      "==============================================================================\n",
      "Omnibus:                      974.639   Durbin-Watson:                   2.285\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1789674.506\n",
      "Skew:                           9.288   Prob(JB):                         0.00\n",
      "Kurtosis:                     273.097   Cond. No.                     9.75e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.75e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Analysis of feature significance\n",
    "\n",
    "for tagg in hashtags:\n",
    "    y = data_hashtag_all[tagg][1:,0] # Number of tweets (except first)\n",
    "    X = np.delete(data_hashtag_all[tagg], -1, 0) # Delete last row\n",
    "    print('Hashtag: '+ tagg)\n",
    "    print('X shape:', X.shape)\n",
    "    print('y shape:', y.shape)\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    print('---------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piece-wise Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: gohawks\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 69706.01044834527 \n",
      " test = 3062922.2893514833\n",
      "R2 measure:\n",
      "   train = 0.7521937746748064 \n",
      " test = -0.7275007245372527\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 84144.7693946039 \n",
      " test = 70632.31242527574\n",
      "R2 measure:\n",
      "   train = 0.5397814216380463 \n",
      " test = 0.2584000640291245\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 1379.202418578555 \n",
      " test = 2749.4407660940706\n",
      "R2 measure:\n",
      "   train = 0.8836412059762403 \n",
      " test = 0.6977142626184509\n",
      "-------------\n",
      "Hashtag: gopatriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 74.4378523492514 \n",
      " test = 4745.15314596021\n",
      "R2 measure:\n",
      "   train = 0.8734956172227551 \n",
      " test = 0.3703393284535915\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 12669.77215309922 \n",
      " test = 15320.43926706397\n",
      "R2 measure:\n",
      "   train = 0.4832540341082566 \n",
      " test = 0.42663201789560945\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 11.413761440242457 \n",
      " test = 228.188431969641\n",
      "R2 measure:\n",
      "   train = 0.9396718037508232 \n",
      " test = -0.644566326267646\n",
      "-------------\n",
      "Hashtag: nfl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 16757.33756238002 \n",
      " test = 119770.73198032069\n",
      "R2 measure:\n",
      "   train = 0.7419359174151553 \n",
      " test = 0.41269425264298965\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 17670.786470509647 \n",
      " test = 26874.11442263643\n",
      "R2 measure:\n",
      "   train = 0.8274258453419989 \n",
      " test = 0.790026019760931\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 18883.368826212016 \n",
      " test = 16940.79757793922\n",
      "R2 measure:\n",
      "   train = 0.7602067654836231 \n",
      " test = 0.8162698599258007\n",
      "-------------\n",
      "Hashtag: patriots\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 88749.63475715564 \n",
      " test = 880810.9335178173\n",
      "R2 measure:\n",
      "   train = 0.5260331496754511 \n",
      " test = 0.3560333122474162\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 446115.3016476706 \n",
      " test = 909534.3676567972\n",
      "R2 measure:\n",
      "   train = 0.7705275413235178 \n",
      " test = 0.6608029311105081\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 15117.730754332379 \n",
      " test = 36867.36796262588\n",
      "R2 measure:\n",
      "   train = 0.844813850129302 \n",
      " test = 0.5527819539123255\n",
      "-------------\n",
      "Hashtag: sb49\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 4597.015895039816 \n",
      " test = 12505.533609735847\n",
      "R2 measure:\n",
      "   train = 0.9332732394173087 \n",
      " test = 0.639111951205195\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 1806484.9171598328 \n",
      " test = 915132.5531722796\n",
      "R2 measure:\n",
      "   train = 0.8037335910199405 \n",
      " test = 0.9076849819969622\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 45450.06737032375 \n",
      " test = 196995.97204321553\n",
      "R2 measure:\n",
      "   train = 0.8832307635665808 \n",
      " test = 0.42637186384243364\n",
      "-------------\n",
      "Hashtag: superbowl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 132911.1452410422 \n",
      " test = 989566.7758186224\n",
      "R2 measure:\n",
      "   train = 0.7627448244648496 \n",
      " test = 0.1462317664687688\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 7207877.843099674 \n",
      " test = 7194741.041233249\n",
      "R2 measure:\n",
      "   train = 0.8581674426346251 \n",
      " test = 0.9025872676676021\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 154625.8478901125 \n",
      " test = 99602.37709521383\n",
      "R2 measure:\n",
      "   train = 0.7748777908951736 \n",
      " test = 0.8632437795838482\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Define train data and targets\n",
    "for tagg in hashtags:\n",
    "    y1 = data_hashtag_before[tagg][1:,0] # Number of tweets (except first)\n",
    "    X1 = np.delete(data_hashtag_before[tagg], -1, 0) # Delete last row\n",
    "    y2 = data_hashtag_during[tagg][1:,0] # Number of tweets (except first)\n",
    "    X2 = np.delete(data_hashtag_during[tagg], -1, 0) # Delete last row\n",
    "    y3 = data_hashtag_after[tagg][1:,0] # Number of tweets (except first)\n",
    "    X3 = np.delete(data_hashtag_after[tagg], -1, 0) # Delete last row\n",
    "    print('Hashtag: '+ tagg)\n",
    "    print('X shape:', X.shape)\n",
    "    print('y shape:', y.shape)\n",
    "    model = LinearRegression()\n",
    "    print('****Before****')\n",
    "    mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X1, y1)\n",
    "    print('****During****')\n",
    "    mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X2, y2)\n",
    "    print('****After****')\n",
    "    mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X3, y3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: superbowl\n",
      "X shape: (586, 5)\n",
      "y shape: (586,)\n",
      "****Before****\n",
      "MSE:\n",
      "   train = 892423.5377543266 \n",
      " test = 8339131.723993236\n",
      "R2 measure:\n",
      "   train = 0.6457624318051375 \n",
      " test = 0.3275373662195967\n",
      "-------------\n",
      "****During****\n",
      "MSE:\n",
      "   train = 18895720.778803244 \n",
      " test = 16714211.339941263\n",
      "R2 measure:\n",
      "   train = 0.8091054443524165 \n",
      " test = 0.8695145932624\n",
      "-------------\n",
      "****After****\n",
      "MSE:\n",
      "   train = 296866.62104623887 \n",
      " test = 1654667.5995643556\n",
      "R2 measure:\n",
      "   train = 0.9097969734280041 \n",
      " test = 0.4702925277273955\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "y1 = data_aggregate_before[1:,0] # Number of tweets (except first)\n",
    "X1 = np.delete(data_aggregate_before, -1, 0) # Delete last row\n",
    "y2 = data_aggregate_during[1:,0] # Number of tweets (except first)\n",
    "X2 = np.delete(data_aggregate_during, -1, 0) # Delete last row\n",
    "y3 = data_aggregate_after[1:,0] # Number of tweets (except first)\n",
    "X3 = np.delete(data_aggregate_after, -1, 0) # Delete last row\n",
    "print('Hashtag: '+ tagg)\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "model = LinearRegression()\n",
    "print('****Before****')\n",
    "mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X1, y1)\n",
    "print('****During****')\n",
    "mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X2, y2)\n",
    "print('****After****')\n",
    "mse_train , mse_test, r2_train, r2_test = analyze_lr(model, X3, y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
